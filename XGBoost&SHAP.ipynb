{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.utils import class_weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder_path= 'E:\\\\Case Comp\\\\NEST\\\\Training\\\\'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yRP7qoRlwHYx"
      },
      "outputs": [],
      "source": [
        "def load_parquet_files(directory):\n",
        "    \"\"\"\n",
        "    Loads all Parquet files within a given directory into a dictionary,\n",
        "    where the keys are the file names (without extension) and the values are\n",
        "    the corresponding DataFrames.\n",
        "\n",
        "    Args:\n",
        "        directory: Path to the directory containing the Parquet files.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary where keys are file names (without extension)\n",
        "        and values are DataFrames read from the corresponding files.\n",
        "    \"\"\"\n",
        "\n",
        "    dataframes = {}\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".parquet\"):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            file_name = filename.split(\".\")[0]  # Extract filename without extension\n",
        "            dataframes[file_name] = pd.read_parquet(filepath)\n",
        "    return dataframes\n",
        "\n",
        "# Example usage:\n",
        "directory = folder_path +\"preprocessed_train\\\\\"   # Replace with the actual directory path\n",
        "dataframes = load_parquet_files(directory)\n",
        "\n",
        "# Access individual DataFrames using their names\n",
        "model_interventional_non_oncology = dataframes['model_interventional_non_oncology']\n",
        "model_interventional_oncology = dataframes['model_interventional_oncology']\n",
        "model_interventional_other = dataframes['model_interventional_other']\n",
        "model_observational_non_oncology = dataframes['model_observational_non_oncology']\n",
        "model_observational_oncology = dataframes['model_observational_oncology']\n",
        "model_observational_other = dataframes['model_observational_other']\n",
        "\n",
        "directory = folder_path +\"preprocessed_test\\\\\"  # Replace with the actual directory path\n",
        "dataframes = load_parquet_files(directory)\n",
        "\n",
        "# Access individual DataFrames using their names\n",
        "test_model_interventional_non_oncology = dataframes['model_interventional_non_oncology']\n",
        "test_model_interventional_oncology = dataframes['model_interventional_oncology']\n",
        "test_model_interventional_other = dataframes['model_interventional_other']\n",
        "test_model_observational_non_oncology = dataframes['model_observational_non_oncology']\n",
        "test_model_observational_oncology = dataframes['model_observational_oncology']\n",
        "test_model_observational_other = dataframes['model_observational_other']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fkP1DY-6xeQt"
      },
      "outputs": [],
      "source": [
        "# Set 'data_split' for train datasets\n",
        "model_interventional_non_oncology['data_split'] = 'train'\n",
        "model_interventional_oncology['data_split'] = 'train'\n",
        "model_interventional_other['data_split'] = 'train'\n",
        "model_observational_non_oncology['data_split'] = 'train'\n",
        "model_observational_oncology['data_split'] = 'train'\n",
        "model_observational_other['data_split'] = 'train'\n",
        "\n",
        "# Set 'data_split' for test datasets\n",
        "test_model_interventional_non_oncology['data_split'] = 'test'\n",
        "test_model_interventional_oncology['data_split'] = 'test'\n",
        "test_model_interventional_other['data_split'] = 'test'\n",
        "test_model_observational_non_oncology['data_split'] = 'test'\n",
        "test_model_observational_oncology['data_split'] = 'test'\n",
        "test_model_observational_other['data_split'] = 'test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4MYiEA8ayhYV"
      },
      "outputs": [],
      "source": [
        "# Set 'data_type' for train datasets\n",
        "model_interventional_non_oncology['data_type'] = 'model_interventional_non_oncology'\n",
        "model_interventional_oncology['data_type'] = 'model_interventional_oncology'\n",
        "model_interventional_other['data_type'] = 'model_interventional_other'\n",
        "model_observational_non_oncology['data_type'] = 'model_observational_non_oncology'\n",
        "model_observational_oncology['data_type'] = 'model_observational_oncology'\n",
        "model_observational_other['data_type'] = 'model_observational_other'\n",
        "\n",
        "# Set 'data_type' for test datasets\n",
        "test_model_interventional_non_oncology['data_type'] = 'model_interventional_non_oncology'\n",
        "test_model_interventional_oncology['data_type'] = 'model_interventional_oncology'\n",
        "test_model_interventional_other['data_type'] = 'model_interventional_other'\n",
        "test_model_observational_non_oncology['data_type'] = 'model_observational_non_oncology'\n",
        "test_model_observational_oncology['data_type'] = 'model_observational_oncology'\n",
        "test_model_observational_other['data_type'] = 'model_observational_other'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "kKvcVsUZyxAg",
        "outputId": "7c783f4e-f544-4083-da05-abb43339e1ea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NCT Number</th>\n",
              "      <th>Study Status</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Enrollment</th>\n",
              "      <th>Funder Type</th>\n",
              "      <th>Study Type</th>\n",
              "      <th>Start Month</th>\n",
              "      <th>Start Quarter</th>\n",
              "      <th>Condition Category</th>\n",
              "      <th>Conditions_Category</th>\n",
              "      <th>...</th>\n",
              "      <th>Brief Summary_Sentence_Count</th>\n",
              "      <th>Brief Summary_Avg_Word_Length</th>\n",
              "      <th>Brief Summary_Sentiment_Score</th>\n",
              "      <th>Total Outcome Measures_Word_Count</th>\n",
              "      <th>Total Outcome Measures_Char_Count</th>\n",
              "      <th>Total Outcome Measures_Sentence_Count</th>\n",
              "      <th>Total Outcome Measures_Avg_Word_Length</th>\n",
              "      <th>Total Outcome Measures_Sentiment_Score</th>\n",
              "      <th>data_split</th>\n",
              "      <th>data_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NCT00421603</td>\n",
              "      <td>Completed</td>\n",
              "      <td>ALL</td>\n",
              "      <td>81.0</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>INTERVENTIONAL</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Other Rare or Unclassified</td>\n",
              "      <td>Non-Oncology</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.737374</td>\n",
              "      <td>0.341667</td>\n",
              "      <td>122.0</td>\n",
              "      <td>628.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.147541</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>train</td>\n",
              "      <td>model_interventional_non_oncology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NCT01340534</td>\n",
              "      <td>Completed</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>370.0</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>INTERVENTIONAL</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>Other Rare or Unclassified</td>\n",
              "      <td>Non-Oncology</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>182.0</td>\n",
              "      <td>994.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.461538</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>train</td>\n",
              "      <td>model_interventional_non_oncology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NCT04166370</td>\n",
              "      <td>Not_Completed</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>INTERVENTIONAL</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>Other Rare or Unclassified</td>\n",
              "      <td>Non-Oncology</td>\n",
              "      <td>...</td>\n",
              "      <td>13.0</td>\n",
              "      <td>6.003236</td>\n",
              "      <td>0.079242</td>\n",
              "      <td>69.0</td>\n",
              "      <td>381.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.521739</td>\n",
              "      <td>-0.312500</td>\n",
              "      <td>train</td>\n",
              "      <td>model_interventional_non_oncology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NCT04670601</td>\n",
              "      <td>Completed</td>\n",
              "      <td>ALL</td>\n",
              "      <td>24.0</td>\n",
              "      <td>INDUSTRY</td>\n",
              "      <td>INTERVENTIONAL</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>Low-Risk Non-Oncology</td>\n",
              "      <td>Non-Oncology</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>6.292683</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>266.0</td>\n",
              "      <td>1259.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.733083</td>\n",
              "      <td>0.086726</td>\n",
              "      <td>train</td>\n",
              "      <td>model_interventional_non_oncology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NCT02158065</td>\n",
              "      <td>Completed</td>\n",
              "      <td>ALL</td>\n",
              "      <td>370.0</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>INTERVENTIONAL</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>Other Rare or Unclassified</td>\n",
              "      <td>Non-Oncology</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.625000</td>\n",
              "      <td>-0.083333</td>\n",
              "      <td>262.0</td>\n",
              "      <td>1437.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.484733</td>\n",
              "      <td>-0.038889</td>\n",
              "      <td>train</td>\n",
              "      <td>model_interventional_non_oncology</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 70 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    NCT Number   Study Status     Sex  Enrollment Funder Type      Study Type  \\\n",
              "0  NCT00421603      Completed     ALL        81.0       OTHER  INTERVENTIONAL   \n",
              "1  NCT01340534      Completed  FEMALE       370.0       OTHER  INTERVENTIONAL   \n",
              "2  NCT04166370  Not_Completed  FEMALE         0.0       OTHER  INTERVENTIONAL   \n",
              "3  NCT04670601      Completed     ALL        24.0    INDUSTRY  INTERVENTIONAL   \n",
              "4  NCT02158065      Completed     ALL       370.0       OTHER  INTERVENTIONAL   \n",
              "\n",
              "   Start Month  Start Quarter          Condition Category Conditions_Category  \\\n",
              "0            2              1  Other Rare or Unclassified        Non-Oncology   \n",
              "1           10              4  Other Rare or Unclassified        Non-Oncology   \n",
              "2           -1             -1  Other Rare or Unclassified        Non-Oncology   \n",
              "3           -1             -1       Low-Risk Non-Oncology        Non-Oncology   \n",
              "4            5              2  Other Rare or Unclassified        Non-Oncology   \n",
              "\n",
              "   ... Brief Summary_Sentence_Count  Brief Summary_Avg_Word_Length  \\\n",
              "0  ...                          5.0                       5.737374   \n",
              "1  ...                          1.0                       5.000000   \n",
              "2  ...                         13.0                       6.003236   \n",
              "3  ...                          2.0                       6.292683   \n",
              "4  ...                          1.0                       5.625000   \n",
              "\n",
              "  Brief Summary_Sentiment_Score Total Outcome Measures_Word_Count  \\\n",
              "0                      0.341667                             122.0   \n",
              "1                      0.000000                             182.0   \n",
              "2                      0.079242                              69.0   \n",
              "3                      0.000000                             266.0   \n",
              "4                     -0.083333                             262.0   \n",
              "\n",
              "  Total Outcome Measures_Char_Count  Total Outcome Measures_Sentence_Count  \\\n",
              "0                             628.0                                    5.0   \n",
              "1                             994.0                                    6.0   \n",
              "2                             381.0                                    1.0   \n",
              "3                            1259.0                                    2.0   \n",
              "4                            1437.0                                    1.0   \n",
              "\n",
              "   Total Outcome Measures_Avg_Word_Length  \\\n",
              "0                                5.147541   \n",
              "1                                5.461538   \n",
              "2                                5.521739   \n",
              "3                                4.733083   \n",
              "4                                5.484733   \n",
              "\n",
              "   Total Outcome Measures_Sentiment_Score data_split  \\\n",
              "0                                0.025000      train   \n",
              "1                                0.500000      train   \n",
              "2                               -0.312500      train   \n",
              "3                                0.086726      train   \n",
              "4                               -0.038889      train   \n",
              "\n",
              "                           data_type  \n",
              "0  model_interventional_non_oncology  \n",
              "1  model_interventional_non_oncology  \n",
              "2  model_interventional_non_oncology  \n",
              "3  model_interventional_non_oncology  \n",
              "4  model_interventional_non_oncology  \n",
              "\n",
              "[5 rows x 70 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine all the DataFrames into one single dataset\n",
        "combined_data = pd.concat([\n",
        "    model_interventional_non_oncology, model_interventional_oncology, model_interventional_other,\n",
        "    model_observational_non_oncology, model_observational_oncology, model_observational_other,\n",
        "    test_model_interventional_non_oncology, test_model_interventional_oncology, test_model_interventional_other,\n",
        "    test_model_observational_non_oncology, test_model_observational_oncology, test_model_observational_other\n",
        "], ignore_index=True)\n",
        "\n",
        "# Drop columns that start with 'Unnamed'\n",
        "combined_data = combined_data.loc[:, ~combined_data.columns.str.startswith('Unnamed')]\n",
        "\n",
        "combined_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuhX-Gg7y4SE",
        "outputId": "58930ea1-23a3-4dcf-f9c4-9fa5d24b955f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['NCT Number',\n",
              " 'Study Status',\n",
              " 'Sex',\n",
              " 'Enrollment',\n",
              " 'Funder Type',\n",
              " 'Study Type',\n",
              " 'Start Month',\n",
              " 'Start Quarter',\n",
              " 'Condition Category',\n",
              " 'Conditions_Category',\n",
              " 'Locations',\n",
              " 'Num_Collaborators',\n",
              " 'Collaborator_Type',\n",
              " 'Condition_Category_old',\n",
              " 'Sponsor Type',\n",
              " 'CHILD',\n",
              " 'ADULT',\n",
              " 'OLDER_ADULT',\n",
              " 'Masking',\n",
              " 'Observational Model',\n",
              " 'Time Perspective',\n",
              " 'Masking Details',\n",
              " 'Allocation_',\n",
              " 'Allocation_NA',\n",
              " 'Allocation_NON_RANDOMIZED',\n",
              " 'Allocation_RANDOMIZED',\n",
              " 'Allocation_Unknown',\n",
              " 'Intervention Model_',\n",
              " 'Intervention Model_CROSSOVER',\n",
              " 'Intervention Model_FACTORIAL',\n",
              " 'Intervention Model_PARALLEL',\n",
              " 'Intervention Model_SEQUENTIAL',\n",
              " 'Intervention Model_SINGLE_GROUP',\n",
              " 'Intervention Model_Unknown',\n",
              " 'Masking Level_DOUBLE',\n",
              " 'Masking Level_NONE',\n",
              " 'Masking Level_QUADRUPLE',\n",
              " 'Masking Level_SINGLE',\n",
              " 'Masking Level_TRIPLE',\n",
              " 'Primary Purpose_',\n",
              " 'Primary Purpose_BASIC_SCIENCE',\n",
              " 'Primary Purpose_DEVICE_FEASIBILITY',\n",
              " 'Primary Purpose_DIAGNOSTIC',\n",
              " 'Primary Purpose_ECT',\n",
              " 'Primary Purpose_HEALTH_SERVICES_RESEARCH',\n",
              " 'Primary Purpose_OTHER',\n",
              " 'Primary Purpose_PREVENTION',\n",
              " 'Primary Purpose_SCREENING',\n",
              " 'Primary Purpose_SUPPORTIVE_CARE',\n",
              " 'Primary Purpose_TREATMENT',\n",
              " 'Primary Purpose_Unknown',\n",
              " 'Country',\n",
              " 'Development Category',\n",
              " 'Study Title_Word_Count',\n",
              " 'Study Title_Char_Count',\n",
              " 'Study Title_Sentence_Count',\n",
              " 'Study Title_Avg_Word_Length',\n",
              " 'Study Title_Sentiment_Score',\n",
              " 'Brief Summary_Word_Count',\n",
              " 'Brief Summary_Char_Count',\n",
              " 'Brief Summary_Sentence_Count',\n",
              " 'Brief Summary_Avg_Word_Length',\n",
              " 'Brief Summary_Sentiment_Score',\n",
              " 'Total Outcome Measures_Word_Count',\n",
              " 'Total Outcome Measures_Char_Count',\n",
              " 'Total Outcome Measures_Sentence_Count',\n",
              " 'Total Outcome Measures_Avg_Word_Length',\n",
              " 'Total Outcome Measures_Sentiment_Score',\n",
              " 'data_split',\n",
              " 'data_type']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(combined_data.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "W1r_L8V3z4Vl",
        "outputId": "8a62c2cb-4d2b-4218-cf8d-73f76c1196ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Study Status\n",
              "Completed                  221243\n",
              "COMPLETED                   55132\n",
              "Not_Completed               36334\n",
              "TERMINATED                   5970\n",
              "WITHDRAWN                    2909\n",
              "SUSPENDED                     299\n",
              "ACTIVE_NOT_RECRUITING          15\n",
              "RECRUITING                     11\n",
              "ENROLLING_BY_INVITATION         1\n",
              "NOT_YET_RECRUITING              1\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_data['Study Status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "xKemIm1QzolX",
        "outputId": "656ecdff-614d-40c0-9532-ce20507aa153"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Study Status\n",
              "1    276375\n",
              "0     45540\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Update 'Study Status' to 1 if 'Completed' or 'COMPLETED', else 0\n",
        "combined_data['Study Status'] = combined_data['Study Status'].apply(lambda x: 1 if x in ['Completed', 'COMPLETED'] else 0)\n",
        "combined_data['Study Status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LHO6fCek1bln"
      },
      "outputs": [],
      "source": [
        "# Remove 'NCT Number' and 'Study Status' from the DataFrame columns\n",
        "combined_data = combined_data.drop(columns=['Locations'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD-vjj3EzYq_",
        "outputId": "1a4e8bb6-6f3e-4ffb-ebb3-ef4383f4f5b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categorical Columns: ['Sex', 'Funder Type', 'Study Type', 'Condition Category', 'Conditions_Category', 'Collaborator_Type', 'Condition_Category_old', 'Sponsor Type', 'Masking', 'Observational Model', 'Time Perspective', 'Masking Details', 'Country', 'Development Category', 'Start Month', 'Start Quarter']\n",
            "Numerical Columns: ['Enrollment', 'Num_Collaborators', 'CHILD', 'ADULT', 'OLDER_ADULT', 'Study Title_Word_Count', 'Study Title_Char_Count', 'Study Title_Sentence_Count', 'Study Title_Avg_Word_Length', 'Study Title_Sentiment_Score', 'Brief Summary_Word_Count', 'Brief Summary_Char_Count', 'Brief Summary_Sentence_Count', 'Brief Summary_Avg_Word_Length', 'Brief Summary_Sentiment_Score', 'Total Outcome Measures_Word_Count', 'Total Outcome Measures_Char_Count', 'Total Outcome Measures_Sentence_Count', 'Total Outcome Measures_Avg_Word_Length', 'Total Outcome Measures_Sentiment_Score']\n"
          ]
        }
      ],
      "source": [
        "# Get categorical columns (object or category type)\n",
        "categorical_columns = combined_data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# Get numerical columns (int, float type)\n",
        "numerical_columns = combined_data.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# Remove 'NCT Number' and 'Study Status' from the lists\n",
        "categorical_columns = [col for col in categorical_columns if col not in ['NCT Number', 'Study Status', 'data_split', 'data_type']]\n",
        "numerical_columns = [col for col in numerical_columns if col not in ['NCT Number', 'Study Status', 'data_split', 'data_type', 'Start Month', 'Start Quarter']]\n",
        "\n",
        "# Explicitly add 'Start Month' and 'Start Quarter' to the categorical columns\n",
        "categorical_columns.extend(['Start Month', 'Start Quarter'])\n",
        "\n",
        "# Optionally, print the lists of categorical and numerical columns\n",
        "print(\"Categorical Columns:\", categorical_columns)\n",
        "print(\"Numerical Columns:\", numerical_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "uo94Rcz3z1bZ",
        "outputId": "62b0b4f0-3051-4ea0-a135-64bc3a2e37ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NCT Number</th>\n",
              "      <th>Study Status</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Enrollment</th>\n",
              "      <th>Funder Type</th>\n",
              "      <th>Study Type</th>\n",
              "      <th>Start Month</th>\n",
              "      <th>Start Quarter</th>\n",
              "      <th>Condition Category</th>\n",
              "      <th>Conditions_Category</th>\n",
              "      <th>...</th>\n",
              "      <th>Total Outcome Measures_Sentence_Count</th>\n",
              "      <th>Total Outcome Measures_Avg_Word_Length</th>\n",
              "      <th>Total Outcome Measures_Sentiment_Score</th>\n",
              "      <th>data_split</th>\n",
              "      <th>data_type</th>\n",
              "      <th>United States</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>France</th>\n",
              "      <th>India</th>\n",
              "      <th>China</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NCT00421603</td>\n",
              "      <td>1</td>\n",
              "      <td>ALL</td>\n",
              "      <td>81.0</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>INTERVENTIONAL</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Other Rare or Unclassified</td>\n",
              "      <td>Non-Oncology</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.147541</td>\n",
              "      <td>0.025000</td>\n",
              "      <td>train</td>\n",
              "      <td>model_interventional_non_oncology</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NCT01340534</td>\n",
              "      <td>1</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>370.0</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>INTERVENTIONAL</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>Other Rare or Unclassified</td>\n",
              "      <td>Non-Oncology</td>\n",
              "      <td>...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.461538</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>train</td>\n",
              "      <td>model_interventional_non_oncology</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NCT04166370</td>\n",
              "      <td>0</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>0.0</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>INTERVENTIONAL</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>Other Rare or Unclassified</td>\n",
              "      <td>Non-Oncology</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.521739</td>\n",
              "      <td>-0.312500</td>\n",
              "      <td>train</td>\n",
              "      <td>model_interventional_non_oncology</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NCT04670601</td>\n",
              "      <td>1</td>\n",
              "      <td>ALL</td>\n",
              "      <td>24.0</td>\n",
              "      <td>INDUSTRY</td>\n",
              "      <td>INTERVENTIONAL</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>Low-Risk Non-Oncology</td>\n",
              "      <td>Non-Oncology</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.733083</td>\n",
              "      <td>0.086726</td>\n",
              "      <td>train</td>\n",
              "      <td>model_interventional_non_oncology</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NCT02158065</td>\n",
              "      <td>1</td>\n",
              "      <td>ALL</td>\n",
              "      <td>370.0</td>\n",
              "      <td>OTHER</td>\n",
              "      <td>INTERVENTIONAL</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>Other Rare or Unclassified</td>\n",
              "      <td>Non-Oncology</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.484733</td>\n",
              "      <td>-0.038889</td>\n",
              "      <td>train</td>\n",
              "      <td>model_interventional_non_oncology</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 73 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    NCT Number  Study Status     Sex  Enrollment Funder Type      Study Type  \\\n",
              "0  NCT00421603             1     ALL        81.0       OTHER  INTERVENTIONAL   \n",
              "1  NCT01340534             1  FEMALE       370.0       OTHER  INTERVENTIONAL   \n",
              "2  NCT04166370             0  FEMALE         0.0       OTHER  INTERVENTIONAL   \n",
              "3  NCT04670601             1     ALL        24.0    INDUSTRY  INTERVENTIONAL   \n",
              "4  NCT02158065             1     ALL       370.0       OTHER  INTERVENTIONAL   \n",
              "\n",
              "   Start Month  Start Quarter          Condition Category Conditions_Category  \\\n",
              "0            2              1  Other Rare or Unclassified        Non-Oncology   \n",
              "1           10              4  Other Rare or Unclassified        Non-Oncology   \n",
              "2           -1             -1  Other Rare or Unclassified        Non-Oncology   \n",
              "3           -1             -1       Low-Risk Non-Oncology        Non-Oncology   \n",
              "4            5              2  Other Rare or Unclassified        Non-Oncology   \n",
              "\n",
              "   ...  Total Outcome Measures_Sentence_Count  \\\n",
              "0  ...                                    5.0   \n",
              "1  ...                                    6.0   \n",
              "2  ...                                    1.0   \n",
              "3  ...                                    2.0   \n",
              "4  ...                                    1.0   \n",
              "\n",
              "  Total Outcome Measures_Avg_Word_Length  \\\n",
              "0                               5.147541   \n",
              "1                               5.461538   \n",
              "2                               5.521739   \n",
              "3                               4.733083   \n",
              "4                               5.484733   \n",
              "\n",
              "  Total Outcome Measures_Sentiment_Score data_split  \\\n",
              "0                               0.025000      train   \n",
              "1                               0.500000      train   \n",
              "2                              -0.312500      train   \n",
              "3                               0.086726      train   \n",
              "4                              -0.038889      train   \n",
              "\n",
              "                           data_type  United States  Unknown France India  \\\n",
              "0  model_interventional_non_oncology              1        0      0     0   \n",
              "1  model_interventional_non_oncology              0        0      0     0   \n",
              "2  model_interventional_non_oncology              0        0      0     0   \n",
              "3  model_interventional_non_oncology              0        0      0     0   \n",
              "4  model_interventional_non_oncology              0        0      0     0   \n",
              "\n",
              "  China  \n",
              "0     0  \n",
              "1     0  \n",
              "2     0  \n",
              "3     0  \n",
              "4     0  \n",
              "\n",
              "[5 rows x 73 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List of top 5 countries\n",
        "top_5_countries = ['United States', 'Unknown', 'France', 'India', 'China']\n",
        "\n",
        "# Create separate columns for each of the top 5 countries\n",
        "for country in top_5_countries:\n",
        "    combined_data[country] = combined_data['Country'].apply(lambda x: 1 if x == country else 0)\n",
        "\n",
        "combined_data = combined_data.drop(columns=['Country'])\n",
        "\n",
        "combined_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S56VKIJJ1vUj"
      },
      "outputs": [],
      "source": [
        "categorical_columns = [col for col in categorical_columns if col not in ['NCT Number', 'Study Status', 'data_split', 'data_type', 'Country']]\n",
        "numerical_columns.extend(['United States', 'Unknown', 'France', 'India', 'China'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "qznKfoPm2g0s",
        "outputId": "a36ecbc7-db2a-4c64-da89-013164113ed6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>NCT Number</th>\n",
              "      <th>Study Status</th>\n",
              "      <th>Enrollment</th>\n",
              "      <th>Num_Collaborators</th>\n",
              "      <th>CHILD</th>\n",
              "      <th>ADULT</th>\n",
              "      <th>OLDER_ADULT</th>\n",
              "      <th>Allocation_</th>\n",
              "      <th>Allocation_NA</th>\n",
              "      <th>Allocation_NON_RANDOMIZED</th>\n",
              "      <th>...</th>\n",
              "      <th>Start Month_7</th>\n",
              "      <th>Start Month_8</th>\n",
              "      <th>Start Month_9</th>\n",
              "      <th>Start Month_10</th>\n",
              "      <th>Start Month_11</th>\n",
              "      <th>Start Month_12</th>\n",
              "      <th>Start Quarter_1</th>\n",
              "      <th>Start Quarter_2</th>\n",
              "      <th>Start Quarter_3</th>\n",
              "      <th>Start Quarter_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NCT00421603</td>\n",
              "      <td>1</td>\n",
              "      <td>81.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NCT01340534</td>\n",
              "      <td>1</td>\n",
              "      <td>370.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NCT04166370</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NCT04670601</td>\n",
              "      <td>1</td>\n",
              "      <td>24.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NCT02158065</td>\n",
              "      <td>1</td>\n",
              "      <td>370.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 168 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    NCT Number  Study Status  Enrollment  Num_Collaborators  CHILD  ADULT  \\\n",
              "0  NCT00421603             1        81.0                  1      0      1   \n",
              "1  NCT01340534             1       370.0                  0      1      1   \n",
              "2  NCT04166370             0         0.0                  1      0      1   \n",
              "3  NCT04670601             1        24.0                  1      0      1   \n",
              "4  NCT02158065             1       370.0                  6      0      1   \n",
              "\n",
              "   OLDER_ADULT  Allocation_  Allocation_NA  Allocation_NON_RANDOMIZED  ...  \\\n",
              "0            0        False          False                      False  ...   \n",
              "1            1        False          False                      False  ...   \n",
              "2            1        False          False                      False  ...   \n",
              "3            0        False          False                      False  ...   \n",
              "4            1        False          False                      False  ...   \n",
              "\n",
              "   Start Month_7  Start Month_8  Start Month_9  Start Month_10  \\\n",
              "0            0.0            0.0            0.0             0.0   \n",
              "1            0.0            0.0            0.0             1.0   \n",
              "2            0.0            0.0            0.0             0.0   \n",
              "3            0.0            0.0            0.0             0.0   \n",
              "4            0.0            0.0            0.0             0.0   \n",
              "\n",
              "   Start Month_11  Start Month_12  Start Quarter_1  Start Quarter_2  \\\n",
              "0             0.0             0.0              1.0              0.0   \n",
              "1             0.0             0.0              0.0              0.0   \n",
              "2             0.0             0.0              0.0              0.0   \n",
              "3             0.0             0.0              0.0              0.0   \n",
              "4             0.0             0.0              0.0              1.0   \n",
              "\n",
              "   Start Quarter_3  Start Quarter_4  \n",
              "0              0.0              0.0  \n",
              "1              0.0              1.0  \n",
              "2              0.0              0.0  \n",
              "3              0.0              0.0  \n",
              "4              0.0              0.0  \n",
              "\n",
              "[5 rows x 168 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create and fit the OneHotEncoder\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=False)  # Correct argument for sparse output\n",
        "\n",
        "# Fit the encoder on the categorical columns of the data\n",
        "encoder.fit(combined_data[categorical_columns])\n",
        "\n",
        "# Transform the categorical columns\n",
        "encoded_columns = encoder.transform(combined_data[categorical_columns])\n",
        "\n",
        "# Create a DataFrame with the one-hot encoded values\n",
        "encoded_df = pd.DataFrame(encoded_columns, columns=encoder.get_feature_names_out(categorical_columns))\n",
        "\n",
        "# Drop the original categorical columns and append the encoded columns\n",
        "combined_data_encoded = combined_data.drop(columns=categorical_columns)\n",
        "combined_data_encoded = pd.concat([combined_data_encoded, encoded_df], axis=1)\n",
        "\n",
        "# Save the encoder for future use\n",
        "joblib.dump(encoder, folder_path + 'one_hot_encoder.pkl')\n",
        "\n",
        "# Optionally, display the first few rows of the encoded data\n",
        "combined_data_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aQfja24If0Oq"
      },
      "outputs": [],
      "source": [
        "# Get the exact feature names after encoding training data\n",
        "final_feature_names = list(combined_data_encoded.columns)\n",
        "\n",
        "# Save feature names for inference\n",
        "with open(folder_path + 'one_hot_encoded_feature_names.json', 'w') as f:\n",
        "    json.dump(final_feature_names, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "QhgeZLHm3dZJ",
        "outputId": "b7de7643-d1b0-4437-8f9e-e2c7afb0cd15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "data_type\n",
              "model_interventional_non_oncology    151938\n",
              "model_interventional_other            66629\n",
              "model_observational_non_oncology      37899\n",
              "model_interventional_oncology         37368\n",
              "model_observational_other             20329\n",
              "model_observational_oncology           7752\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "combined_data_encoded.data_type.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBn4QPYK6ycV",
        "outputId": "b4723571-c9ae-4385-f27b-8d76786e0dbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NCT Number: NCT00421603\n",
            "Study Status: 1\n",
            "Enrollment: 81.0\n",
            "Num_Collaborators: 1\n",
            "CHILD: 0\n",
            "ADULT: 1\n",
            "OLDER_ADULT: 0\n",
            "Allocation_: False\n",
            "Allocation_NA: False\n",
            "Allocation_NON_RANDOMIZED: False\n",
            "Allocation_RANDOMIZED: True\n",
            "Allocation_Unknown: False\n",
            "Intervention Model_: False\n",
            "Intervention Model_CROSSOVER: False\n",
            "Intervention Model_FACTORIAL: False\n",
            "Intervention Model_PARALLEL: True\n",
            "Intervention Model_SEQUENTIAL: False\n",
            "Intervention Model_SINGLE_GROUP: False\n",
            "Intervention Model_Unknown: False\n",
            "Masking Level_DOUBLE: False\n",
            "Masking Level_NONE: False\n",
            "Masking Level_QUADRUPLE: False\n",
            "Masking Level_SINGLE: False\n",
            "Masking Level_TRIPLE: True\n",
            "Primary Purpose_: False\n",
            "Primary Purpose_BASIC_SCIENCE: False\n",
            "Primary Purpose_DEVICE_FEASIBILITY: False\n",
            "Primary Purpose_DIAGNOSTIC: False\n",
            "Primary Purpose_ECT: False\n",
            "Primary Purpose_HEALTH_SERVICES_RESEARCH: False\n",
            "Primary Purpose_OTHER: False\n",
            "Primary Purpose_PREVENTION: False\n",
            "Primary Purpose_SCREENING: False\n",
            "Primary Purpose_SUPPORTIVE_CARE: False\n",
            "Primary Purpose_TREATMENT: True\n",
            "Primary Purpose_Unknown: False\n",
            "Study Title_Word_Count: 15.0\n",
            "Study Title_Char_Count: 94.0\n",
            "Study Title_Sentence_Count: 1.0\n",
            "Study Title_Avg_Word_Length: 6.266666666666667\n",
            "Study Title_Sentiment_Score: 0.0\n",
            "Brief Summary_Word_Count: 99.0\n",
            "Brief Summary_Char_Count: 568.0\n",
            "Brief Summary_Sentence_Count: 5.0\n",
            "Brief Summary_Avg_Word_Length: 5.737373737373737\n",
            "Brief Summary_Sentiment_Score: 0.3416666666666666\n",
            "Total Outcome Measures_Word_Count: 122.0\n",
            "Total Outcome Measures_Char_Count: 628.0\n",
            "Total Outcome Measures_Sentence_Count: 5.0\n",
            "Total Outcome Measures_Avg_Word_Length: 5.147540983606557\n",
            "Total Outcome Measures_Sentiment_Score: 0.02500000000000001\n",
            "data_split: train\n",
            "data_type: model_interventional_non_oncology\n",
            "United States: 1\n",
            "Unknown: 0\n",
            "France: 0\n",
            "India: 0\n",
            "China: 0\n",
            "Sex_FEMALE: 0.0\n",
            "Sex_MALE: 0.0\n",
            "Funder Type_FED: 0.0\n",
            "Funder Type_INDIV: 0.0\n",
            "Funder Type_INDUSTRY: 0.0\n",
            "Funder Type_NETWORK: 0.0\n",
            "Funder Type_NIH: 0.0\n",
            "Funder Type_OTHER: 1.0\n",
            "Funder Type_OTHER_GOV: 0.0\n",
            "Funder Type_UNKNOWN: 0.0\n",
            "Study Type_OBSERVATIONAL: 0.0\n",
            "Condition Category_Endocrinology & Metabolic: 0.0\n",
            "Condition Category_Gastroenterology: 0.0\n",
            "Condition Category_High-Risk Non-Oncology: 0.0\n",
            "Condition Category_Infectious Diseases: 0.0\n",
            "Condition Category_Low-Risk Non-Oncology: 0.0\n",
            "Condition Category_Mental Health Disorders: 0.0\n",
            "Condition Category_Moderate-Risk Non-Oncology: 0.0\n",
            "Condition Category_Musculoskeletal & Pain: 0.0\n",
            "Condition Category_Oncology: 0.0\n",
            "Condition Category_Other Rare or Unclassified: 1.0\n",
            "Condition Category_Rare Genetic Disorders: 0.0\n",
            "Condition Category_nan: 0.0\n",
            "Conditions_Category_Oncology: 0.0\n",
            "Conditions_Category_Other Rare or Unclassified: 0.0\n",
            "Collaborator_Type_Contract Research Organization (CRO): 0.0\n",
            "Collaborator_Type_Foundation (Funding Organization): 0.0\n",
            "Collaborator_Type_Government: 1.0\n",
            "Collaborator_Type_Healthcare Consortium/Alliance: 0.0\n",
            "Collaborator_Type_Hospital/Medical Center: 0.0\n",
            "Collaborator_Type_Medical Device Company: 0.0\n",
            "Collaborator_Type_Military/Defense Medical Research: 0.0\n",
            "Collaborator_Type_Non-Academic Research Institute: 0.0\n",
            "Collaborator_Type_Non-Profit / Patient Advocacy: 0.0\n",
            "Collaborator_Type_Other: 0.0\n",
            "Collaborator_Type_Pharmaceutical/Biotech: 0.0\n",
            "Collaborator_Type_University: 0.0\n",
            "Collaborator_Type_Unknown: 0.0\n",
            "Condition_Category_old_Cancer: 0.0\n",
            "Condition_Category_old_Cardiovascular: 0.0\n",
            "Condition_Category_old_Endocrine/Metabolic: 0.0\n",
            "Condition_Category_old_Gastrointestinal & Hepatic: 0.0\n",
            "Condition_Category_old_General Health & Others: 0.0\n",
            "Condition_Category_old_Infectious Diseases: 0.0\n",
            "Condition_Category_old_Musculoskeletal: 0.0\n",
            "Condition_Category_old_Neurological: 0.0\n",
            "Condition_Category_old_Other: 1.0\n",
            "Condition_Category_old_Psychiatric & Behavioral: 0.0\n",
            "Condition_Category_old_Reproductive & Urological: 0.0\n",
            "Condition_Category_old_Respiratory: 0.0\n",
            "Sponsor Type_Government Institute: 1.0\n",
            "Sponsor Type_Hospital/Clinic: 0.0\n",
            "Sponsor Type_Other: 0.0\n",
            "Sponsor Type_University: 0.0\n",
            "Masking_DOUBLE: 0.0\n",
            "Masking_DOUBLE (CARE_PROVIDER, INVESTIGATOR): 0.0\n",
            "Masking_DOUBLE (CARE_PROVIDER, OUTCOMES_ASSESSOR): 0.0\n",
            "Masking_DOUBLE (INVESTIGATOR, OUTCOMES_ASSESSOR): 0.0\n",
            "Masking_DOUBLE (PARTICIPANT, CARE_PROVIDER): 0.0\n",
            "Masking_DOUBLE (PARTICIPANT, INVESTIGATOR): 0.0\n",
            "Masking_DOUBLE (PARTICIPANT, OUTCOMES_ASSESSOR): 0.0\n",
            "Masking_NONE: 0.0\n",
            "Masking_QUADRUPLE (PARTICIPANT, CARE_PROVIDER, INVESTIGATOR, OUTCOMES_ASSESSOR): 0.0\n",
            "Masking_SINGLE: 0.0\n",
            "Masking_SINGLE (CARE_PROVIDER): 0.0\n",
            "Masking_SINGLE (INVESTIGATOR): 0.0\n",
            "Masking_SINGLE (OUTCOMES_ASSESSOR): 0.0\n",
            "Masking_SINGLE (PARTICIPANT): 0.0\n",
            "Masking_TRIPLE (CARE_PROVIDER, INVESTIGATOR, OUTCOMES_ASSESSOR): 0.0\n",
            "Masking_TRIPLE (PARTICIPANT, CARE_PROVIDER, INVESTIGATOR): 0.0\n",
            "Masking_TRIPLE (PARTICIPANT, CARE_PROVIDER, OUTCOMES_ASSESSOR): 0.0\n",
            "Masking_TRIPLE (PARTICIPANT, INVESTIGATOR, OUTCOMES_ASSESSOR): 1.0\n",
            "Masking_None: 0.0\n",
            "Observational Model_Unknown: 1.0\n",
            "Time Perspective_p: 0.0\n",
            "Masking Details_CARE_PROVIDER, INVESTIGATOR: 0.0\n",
            "Masking Details_CARE_PROVIDER, INVESTIGATOR, OUTCOMES_ASSESSOR: 0.0\n",
            "Masking Details_CARE_PROVIDER, OUTCOMES_ASSESSOR: 0.0\n",
            "Masking Details_INVESTIGATOR: 0.0\n",
            "Masking Details_INVESTIGATOR, OUTCOMES_ASSESSOR: 0.0\n",
            "Masking Details_NONE: 0.0\n",
            "Masking Details_OUTCOMES_ASSESSOR: 0.0\n",
            "Masking Details_PARTICIPANT: 0.0\n",
            "Masking Details_PARTICIPANT, CARE_PROVIDER: 0.0\n",
            "Masking Details_PARTICIPANT, CARE_PROVIDER, INVESTIGATOR: 0.0\n",
            "Masking Details_PARTICIPANT, CARE_PROVIDER, INVESTIGATOR, OUTCOMES_ASSESSOR: 0.0\n",
            "Masking Details_PARTICIPANT, CARE_PROVIDER, OUTCOMES_ASSESSOR: 0.0\n",
            "Masking Details_PARTICIPANT, INVESTIGATOR: 0.0\n",
            "Masking Details_PARTICIPANT, INVESTIGATOR, OUTCOMES_ASSESSOR: 1.0\n",
            "Masking Details_PARTICIPANT, OUTCOMES_ASSESSOR: 0.0\n",
            "Development Category_Developing: 0.0\n",
            "Development Category_Other Institutions: 0.0\n",
            "Development Category_Underdeveloped: 0.0\n",
            "Development Category_Unknown: 0.0\n",
            "Start Month_1: 0.0\n",
            "Start Month_2: 1.0\n",
            "Start Month_3: 0.0\n",
            "Start Month_4: 0.0\n",
            "Start Month_5: 0.0\n",
            "Start Month_6: 0.0\n",
            "Start Month_7: 0.0\n",
            "Start Month_8: 0.0\n",
            "Start Month_9: 0.0\n",
            "Start Month_10: 0.0\n",
            "Start Month_11: 0.0\n",
            "Start Month_12: 0.0\n",
            "Start Quarter_1: 1.0\n",
            "Start Quarter_2: 0.0\n",
            "Start Quarter_3: 0.0\n",
            "Start Quarter_4: 0.0\n"
          ]
        }
      ],
      "source": [
        "for col in combined_data_encoded.columns:\n",
        "    print(f\"{col}: {combined_data_encoded[col].iloc[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SHAP summary plot saved for model_interventional_non_oncology at E:\\Case Comp\\NEST\\Training\\models/shap_summary_model_interventional_non_oncology.png\n",
            "Accuracy (model_interventional_non_oncology): 0.5831981728509483\n",
            "SHAP summary plot saved for model_interventional_oncology at E:\\Case Comp\\NEST\\Training\\models/shap_summary_model_interventional_oncology.png\n",
            "Accuracy (model_interventional_oncology): 0.6123588039867109\n",
            "SHAP summary plot saved for model_interventional_other at E:\\Case Comp\\NEST\\Training\\models/shap_summary_model_interventional_other.png\n",
            "Accuracy (model_interventional_other): 0.5992469879518072\n",
            "SHAP summary plot saved for model_observational_non_oncology at E:\\Case Comp\\NEST\\Training\\models/shap_summary_model_observational_non_oncology.png\n",
            "Accuracy (model_observational_non_oncology): 0.6432997676219985\n",
            "SHAP summary plot saved for model_observational_oncology at E:\\Case Comp\\NEST\\Training\\models/shap_summary_model_observational_oncology.png\n",
            "Accuracy (model_observational_oncology): 0.662936142198815\n",
            "SHAP summary plot saved for model_observational_other at E:\\Case Comp\\NEST\\Training\\models/shap_summary_model_observational_other.png\n",
            "Accuracy (model_observational_other): 0.6443184619176732\n",
            "✅ Combined predictions, models, and SHAP plots have been saved.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import shap\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# List of data types for creating separate models\n",
        "data_types = [\n",
        "    'model_interventional_non_oncology', 'model_interventional_oncology', 'model_interventional_other',\n",
        "    'model_observational_non_oncology', 'model_observational_oncology', 'model_observational_other'\n",
        "]\n",
        "\n",
        "# Initialize an empty list to store results\n",
        "combined_results = []\n",
        "model_params = {}  # Dictionary to store models and features info\n",
        "\n",
        "# Create a directory to store the models and SHAP plots if it doesn't exist\n",
        "output_dir = os.path.join(folder_path, 'models/')\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "def train_xgboost_model(X_train, y_train):\n",
        "    \"\"\"Trains an XGBoost classifier model with class weights.\"\"\"\n",
        "\n",
        "    # Calculate class weights\n",
        "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "    weight_dict = {i: w if i == 0 else w for i, w in enumerate(class_weights)}\n",
        "    sample_weights = np.array([weight_dict[t] for t in y_train])\n",
        "\n",
        "    # Create DMatrix using sample weights\n",
        "    dtrain = xgb.DMatrix(X_train, label=y_train, weight=sample_weights)\n",
        "\n",
        "    # Set up the parameters\n",
        "    params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'logloss',\n",
        "        'max_depth': 3,\n",
        "        'eta': 0.1\n",
        "    }\n",
        "\n",
        "    # Train the model\n",
        "    model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "\n",
        "    return model, params\n",
        "\n",
        "# Loop over each data type\n",
        "for data_type in data_types:\n",
        "    # Filter data by data_type and data_split (train data)\n",
        "    train_data = combined_data_encoded[\n",
        "        (combined_data_encoded['data_type'] == data_type) & (combined_data_encoded['data_split'] == 'train')\n",
        "    ]\n",
        "    test_data = combined_data_encoded[\n",
        "        (combined_data_encoded['data_type'] == data_type) & (combined_data_encoded['data_split'] == 'test')\n",
        "    ]\n",
        "\n",
        "    # Define features (X) and target (y) for train and test data\n",
        "    X_train = train_data.drop(columns=['Study Status', 'data_split', 'data_type', 'NCT Number', 'Enrollment'])\n",
        "    y_train = train_data['Study Status']\n",
        "    X_test = test_data.drop(columns=['Study Status', 'data_split', 'data_type', 'NCT Number', 'Enrollment'])\n",
        "    y_test = test_data['Study Status']\n",
        "\n",
        "    # Train the XGBoost model with class balancing using the custom training function\n",
        "    model, params = train_xgboost_model(X_train, y_train)\n",
        "\n",
        "    # Save the trained model\n",
        "    model_filename = f\"{data_type}_xgboost_model.json\"\n",
        "    model.save_model(os.path.join(output_dir, model_filename))\n",
        "\n",
        "    # Save the features used for the model\n",
        "    feature_filename = f\"{data_type}_features.json\"\n",
        "    features = list(X_train.columns)\n",
        "    with open(os.path.join(output_dir, feature_filename), 'w') as f:\n",
        "        json.dump(features, f)\n",
        "\n",
        "    # Store the model parameters and feature information\n",
        "    model_params[data_type] = {\n",
        "        'params': params,\n",
        "        'features': features,\n",
        "        'model_filename': model_filename,\n",
        "        'feature_filename': feature_filename\n",
        "    }\n",
        "\n",
        "    # Predict on the test set (get class labels and probabilities)\n",
        "    dtest = xgb.DMatrix(X_test)\n",
        "    y_pred_test = model.predict(dtest)\n",
        "    y_pred_class_test = np.round(y_pred_test)\n",
        "    y_pred_proba_test = np.vstack([1 - y_pred_test, y_pred_test]).T\n",
        "\n",
        "    # Predict on the train set\n",
        "    dtrain = xgb.DMatrix(X_train)\n",
        "    y_pred_train = model.predict(dtrain)\n",
        "    y_pred_class_train = np.round(y_pred_train)\n",
        "    y_pred_proba_train = np.vstack([1 - y_pred_train, y_pred_train]).T\n",
        "\n",
        "    # Prepare final predictions for the test set with NCT Number\n",
        "    final_predictions_test = pd.DataFrame({\n",
        "        \"true_label\": y_test,\n",
        "        \"predicted_class\": y_pred_class_test,\n",
        "        \"prob_class_0\": y_pred_proba_test[:, 0],\n",
        "        \"prob_class_1\": y_pred_proba_test[:, 1],\n",
        "        \"NCT Number\": test_data[\"NCT Number\"],\n",
        "        \"data_split\": \"test\",\n",
        "        \"data_type\": data_type\n",
        "    })\n",
        "\n",
        "    # Prepare final predictions for the train set with NCT Number\n",
        "    final_predictions_train = pd.DataFrame({\n",
        "        \"true_label\": y_train,\n",
        "        \"predicted_class\": y_pred_class_train,\n",
        "        \"prob_class_0\": y_pred_proba_train[:, 0],\n",
        "        \"prob_class_1\": y_pred_proba_train[:, 1],\n",
        "        \"NCT Number\": train_data[\"NCT Number\"],\n",
        "        \"data_split\": \"train\",\n",
        "        \"data_type\": data_type\n",
        "    })\n",
        "\n",
        "    # Append both train and test predictions into the combined results\n",
        "    combined_results.append(final_predictions_test)\n",
        "    combined_results.append(final_predictions_train)\n",
        "\n",
        "    # Calculate SHAP values\n",
        "    shap_values = model.predict(dtest, pred_contribs=True)[:, :-1]\n",
        "\n",
        "    # Save SHAP Summary Plot\n",
        "    plt.figure()\n",
        "    shap.summary_plot(shap_values, X_test, feature_names=X_test.columns, show=False)\n",
        "    shap_filename = os.path.join(output_dir, f\"shap_summary_{data_type}.png\")\n",
        "    plt.savefig(shap_filename)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"SHAP summary plot saved for {data_type} at {shap_filename}\")\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, (y_pred_test > 0.5).astype(int))\n",
        "    print(f\"Accuracy ({data_type}): {accuracy}\")\n",
        "\n",
        "# Combine all results into a single DataFrame and save\n",
        "combined_predictions = pd.concat(combined_results, ignore_index=True)\n",
        "combined_predictions.to_csv(os.path.join(folder_path, 'combined_predictions.csv'), index=False)\n",
        "\n",
        "# Save model parameters for inference\n",
        "with open(os.path.join(output_dir, 'model_params.json'), 'w') as f:\n",
        "    json.dump(model_params, f)\n",
        "\n",
        "print(\"✅ Combined predictions, models, and SHAP plots have been saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB83QcIgOxws",
        "outputId": "41be1841-18d9-472a-adff-6fc4b3c12c5d"
      },
      "outputs": [],
      "source": [
        "# # List of data types for creating separate models\n",
        "# data_types = ['model_interventional_non_oncology', 'model_interventional_oncology', 'model_interventional_other',\n",
        "#               'model_observational_non_oncology', 'model_observational_oncology', 'model_observational_other']\n",
        "\n",
        "# # Initialize an empty list to store results\n",
        "# combined_results = []\n",
        "# model_params = {}  # Dictionary to store models and features info\n",
        "\n",
        "# def train_xgboost_model(X_train, y_train):\n",
        "#     \"\"\"Trains an XGBoost classifier model with class weights.\"\"\"\n",
        "\n",
        "#     # Calculate class weights\n",
        "#     class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "#     weight_dict = {i: w * 1 if i == 0 else w for i, w in enumerate(class_weights)}  # Apply 100x weight to class 0\n",
        "#     sample_weights = np.array([weight_dict[t] for t in y_train])\n",
        "\n",
        "#     # Create DMatrix using sample weights\n",
        "#     dtrain = xgb.DMatrix(X_train, label=y_train, weight=sample_weights)  # Use sample weights in DMatrix\n",
        "\n",
        "#     # Set up the parameters\n",
        "#     params = {\n",
        "#         'objective': 'binary:logistic',\n",
        "#         'eval_metric': 'logloss',\n",
        "#         'max_depth': 3,\n",
        "#         'eta': 0.1\n",
        "#     }\n",
        "\n",
        "#     # Train the model\n",
        "#     model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "\n",
        "#     return model, params\n",
        "\n",
        "# # Create a directory to store the models and feature sets if it doesn't exist\n",
        "# output_dir = folder_path+ 'models\\\\'\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# # Loop over each data type\n",
        "# for data_type in data_types:\n",
        "#     # Filter data by data_type and data_split (train data)\n",
        "#     train_data = combined_data_encoded[(combined_data_encoded['data_type'] == data_type) & (combined_data_encoded['data_split'] == 'train')]\n",
        "#     test_data = combined_data_encoded[(combined_data_encoded['data_type'] == data_type) & (combined_data_encoded['data_split'] == 'test')]\n",
        "\n",
        "#     # Define features (X) and target (y) for train data\n",
        "#     X_train = train_data.drop(columns=['Study Status', 'data_split', 'data_type', 'NCT Number', 'Enrollment'])\n",
        "#     y_train = train_data['Study Status']\n",
        "\n",
        "#     # Define features (X) and target (y) for test data\n",
        "#     X_test = test_data.drop(columns=['Study Status', 'data_split', 'data_type', 'NCT Number', 'Enrollment'])\n",
        "#     y_test = test_data['Study Status']\n",
        "\n",
        "#     # Train the XGBoost model with class balancing using the custom training function\n",
        "#     model, params = train_xgboost_model(X_train, y_train)\n",
        "\n",
        "#     # Save the trained model\n",
        "#     model_filename = f\"{data_type}_xgboost_model.json\"\n",
        "#     model.save_model(os.path.join(output_dir, model_filename))\n",
        "\n",
        "#     # Save the features used for the model\n",
        "#     feature_filename = f\"{data_type}_features.json\"\n",
        "#     features = list(X_train.columns)\n",
        "#     with open(os.path.join(output_dir, feature_filename), 'w') as f:\n",
        "#         json.dump(features, f)\n",
        "\n",
        "#     # Store the model parameters and feature information\n",
        "#     model_params[data_type] = {\n",
        "#         'params': params,\n",
        "#         'features': features,\n",
        "#         'model_filename': model_filename,\n",
        "#         'feature_filename': feature_filename\n",
        "#     }\n",
        "\n",
        "#     # Predict on the test set (get class labels)\n",
        "#     y_pred_test = model.predict(xgb.DMatrix(X_test))\n",
        "#     y_pred_class_test = np.round(y_pred_test)  # Convert probabilities to class labels (0 or 1)\n",
        "\n",
        "#     # Get predicted probabilities for both classes\n",
        "#     y_pred_proba_test = model.predict(xgb.DMatrix(X_test))\n",
        "\n",
        "#     # If the model outputs probabilities for a single class, we need to adjust for binary classification\n",
        "#     if y_pred_proba_test.ndim == 1:  # Only one probability returned\n",
        "#         y_pred_proba_test = np.vstack([1 - y_pred_proba_test, y_pred_proba_test]).T  # Create a 2D array: class 0 and class 1 probabilities\n",
        "\n",
        "#     # Predict on the train set (get class labels)\n",
        "#     y_pred_train = model.predict(xgb.DMatrix(X_train))\n",
        "#     y_pred_class_train = np.round(y_pred_train)  # Convert probabilities to class labels (0 or 1)\n",
        "\n",
        "#     # Get predicted probabilities for both classes for the train set\n",
        "#     y_pred_proba_train = model.predict(xgb.DMatrix(X_train))\n",
        "\n",
        "#     # If the model outputs probabilities for a single class, we need to adjust for binary classification\n",
        "#     if y_pred_proba_train.ndim == 1:  # Only one probability returned\n",
        "#         y_pred_proba_train = np.vstack([1 - y_pred_proba_train, y_pred_proba_train]).T  # Create a 2D array: class 0 and class 1 probabilities\n",
        "\n",
        "#     # Prepare final predictions for the test set with NCT Number\n",
        "#     final_predictions_test = pd.DataFrame()\n",
        "#     final_predictions_test['true_label'] = y_test\n",
        "#     final_predictions_test['predicted_class'] = y_pred_class_test\n",
        "#     final_predictions_test['prob_class_0'] = y_pred_proba_test[:, 0]  # Probability of class 0\n",
        "#     final_predictions_test['prob_class_1'] = y_pred_proba_test[:, 1]  # Probability of class 1\n",
        "#     final_predictions_test['NCT Number'] = test_data['NCT Number']\n",
        "#     final_predictions_test['data_split'] = 'test'  # Add data_split marker\n",
        "#     final_predictions_test['data_type'] = data_type  # Add data_type marker\n",
        "\n",
        "#     # Prepare final predictions for the train set with NCT Number\n",
        "#     final_predictions_train = pd.DataFrame()\n",
        "#     final_predictions_train['true_label'] = y_train\n",
        "#     final_predictions_train['predicted_class'] = y_pred_class_train\n",
        "#     final_predictions_train['prob_class_0'] = y_pred_proba_train[:, 0]  # Probability of class 0\n",
        "#     final_predictions_train['prob_class_1'] = y_pred_proba_train[:, 1]  # Probability of class 1\n",
        "#     final_predictions_train['NCT Number'] = train_data['NCT Number']\n",
        "#     final_predictions_train['data_split'] = 'train'  # Add data_split marker\n",
        "#     final_predictions_train['data_type'] = data_type  # Add data_type marker\n",
        "\n",
        "#     # Append both train and test predictions into the combined results\n",
        "#     combined_results.append(final_predictions_test)\n",
        "#     combined_results.append(final_predictions_train)\n",
        "\n",
        "# # Combine all results into a single DataFrame\n",
        "# combined_predictions = pd.concat(combined_results, ignore_index=True)\n",
        "\n",
        "# # Save the combined predictions to a single CSV file\n",
        "# combined_predictions.to_csv(folder_path +'combined_predictions.csv', index=False)\n",
        "\n",
        "# # Save the model parameters (used for inference) to a JSON file\n",
        "# with open(folder_path + 'models\\\\model_params.json', 'w') as f:\n",
        "#     json.dump(model_params, f)\n",
        "\n",
        "# print(\"Combined predictions and models have been saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "ABBXa6TL-0M2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NEST",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
